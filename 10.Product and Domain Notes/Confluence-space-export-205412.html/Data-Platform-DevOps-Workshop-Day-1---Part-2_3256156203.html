<!DOCTYPE html>
<html>
    <head>
        <title>Jackson Fan : Data Platform DevOps Workshop Day 1 - Part 2</title>
        <link rel="stylesheet" href="styles/site.css" type="text/css" />
        <META http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>

    <body class="theme-default aui-theme-default">
        <div id="page">
            <div id="main" class="aui-page-panel">
                <div id="main-header">
                    <div id="breadcrumb-section">
                        <ol id="breadcrumbs">
                            <li class="first">
                                <span><a href="index.html">Jackson Fan</a></span>
                            </li>
                                                    <li>
                                <span><a href="JF-Space-Overview_2554888272.html">JF Space Overview</a></span>
                            </li>
                                                </ol>
                    </div>
                    <h1 id="title-heading" class="pagetitle">
                                                <span id="title-text">
                            Jackson Fan : Data Platform DevOps Workshop Day 1 - Part 2
                        </span>
                    </h1>
                </div>

                <div id="content" class="view">
                    <div class="page-metadata">
                            
        
    
        
    
        
        
            Created by <span class='author'> Jackson Fan</span>, last modified on 18-07-25
                        </div>
                    <div id="main-content" class="wiki-content group">
                    <h2 id="DataPlatformDevOpsWorkshopDay1-Part2-OverviewoftheSynapseCI/CDPipelineStructure">Overview of the Synapse CI/CD Pipeline Structure</h2><p>Deploying Azure Synapse Analytics artifacts (pipelines, datasets, notebooks, etc.) and SQL database schema changes (via DACPAC) can be automated using Azure DevOps CI/CD pipelines. </p><p>In a typical setup, you have multiple environments (Dev, UAT, PreProd, Prod), and you want to promote Synapse workspace changes and database updates through these stages in a controlled way. </p><p>The Azure DevOps project (e.g. <strong>BI-Synapse-Bedrock</strong>) will contain release pipelines or pipeline stages for each environment. </p><p>For example, one might have a pipeline <strong>Deploy Synapse Analytics Objects – Prod</strong> for Synapse artifacts and another <strong>Release Synapse SQL Pool to Prod</strong> for the database DACPAC deployment, with similar pipelines for UAT, PreProd, and Dev. </p><p>This guide will walk through the end-to-end process of setting up such pipelines, from source control to environment configuration and deployment tasks, with clarity on each step.</p><h2 id="DataPlatformDevOpsWorkshopDay1-Part2-Part1-SourceControlSetupforSynapseArtifactsandDatabaseProjects">Part 1 - Source Control Setup for Synapse Artifacts and Database Projects</h2><p>Before configuring the pipeline, ensure your source code is properly version-controlled:</p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212623.png" width="760" loading="lazy" src="attachments/3256156203/3256614980.png?width=760" data-image-src="attachments/3256156203/3256614980.png" data-height="592" data-width="1552" data-unresolved-comment-count="0" data-linked-resource-id="3256614980" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212623.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="74056ce3-ce2f-4783-8e82-1841d166c182" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212852.png" width="760" loading="lazy" src="attachments/3256156203/3256713269.png?width=760" data-image-src="attachments/3256156203/3256713269.png" data-height="601" data-width="1273" data-unresolved-comment-count="0" data-linked-resource-id="3256713269" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212852.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="b9ea3bf5-0235-4fa6-9dd5-676d00c11d47" data-media-type="file"></span><p /><ul><li><p><strong>Synapse Workspace Artifacts Repository:</strong> </p></li><li><p>In Synapse Studio, connect your Synapse workspace to a Git repository (Azure Repos). Use a collaboration branch (e.g. <em>main</em> or <em>development</em>) for daily work, </p></li><li><p>and set up a publish branch (often named <strong>workspace_publish</strong>) where Synapse will publish deployment templates. When you click <strong>Publish</strong> in Synapse, it generates two JSON files in the publish branch: <strong><span style="background-color: rgb(211,241,167);">TemplateForWorkspace.json</span></strong><span style="background-color: rgb(211,241,167);"> and </span><strong><span style="background-color: rgb(211,241,167);">TemplateParametersForWorkspace.json</span></strong><span style="background-color: rgb(211,241,167);">,</span> which represent the entire workspace (all pipelines, datasets, etc.) and their parameters. </p></li></ul><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212358.png" width="760" loading="lazy" src="attachments/3256156203/3256680476.png?width=760" data-image-src="attachments/3256156203/3256680476.png" data-height="739" data-width="1576" data-unresolved-comment-count="0" data-linked-resource-id="3256680476" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212358.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="5a0898c3-8678-43e2-bb85-0f852ce63822" data-media-type="file"></span><ul><li><p>The publish branch is automatically created upon linking the workspace to Git, and it keeps an up-to-date ARM template of your Synapse workspace. This template will be the basis for deployments to other environments.</p></li><li><p><strong>(BI-Databases) Database Project for DACPAC:</strong> If you have an Azure SQL Database or Synapse Dedicated SQL Pool project, manage its schema in a SQL Database Project (e.g. a <em>.sqlproj</em> in Visual Studio or Azure Data Studio). Store this project in a repo (it can be the same repo or a separate one). Use Azure DevOps pipelines to build the project into a DACPAC file (a packaged database schema). For example, a build pipeline can compile the <em>.sqlproj</em> and produce a <strong>.dacpac</strong> artifact using MSBuild or <code>SqlPackage</code>. This DACPAC will be released to target environments. (If you prefer, you can also keep a ready-made DACPAC in the repo, but using a build pipeline ensures it’s generated from the latest source).</p></li><li><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212518.png" width="736" loading="lazy" src="attachments/3256156203/3256614972.png?width=736" data-image-src="attachments/3256156203/3256614972.png" data-height="718" data-width="1350" data-unresolved-comment-count="0" data-linked-resource-id="3256614972" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212518.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="28604727-a68c-467b-a983-96d13720bf3f" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212544.png" width="736" loading="lazy" src="attachments/3256156203/3256680484.png?width=736" data-image-src="attachments/3256156203/3256680484.png" data-height="726" data-width="1569" data-unresolved-comment-count="0" data-linked-resource-id="3256680484" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212544.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="6c13f6b5-e3c4-4c4c-9a2d-22f826031e4d" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212552.png" width="736" loading="lazy" src="attachments/3256156203/3256713258.png?width=736" data-image-src="attachments/3256156203/3256713258.png" data-height="729" data-width="1572" data-unresolved-comment-count="0" data-linked-resource-id="3256713258" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212552.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="fc16f636-0f5b-4e76-8f24-fc0f1f4775e6" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212559.png" width="736" loading="lazy" src="attachments/3256156203/3256680491.png?width=736" data-image-src="attachments/3256156203/3256680491.png" data-height="675" data-width="1299" data-unresolved-comment-count="0" data-linked-resource-id="3256680491" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212559.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="4c6bc229-fe98-4958-87bb-af05012c1b55" data-media-type="file"></span><p /></li></ul><h2 id="DataPlatformDevOpsWorkshopDay1-Part2-Part2-PreparingAzureDevOps–ProjectandServiceConnections">Part 2 - Preparing Azure DevOps – Project and Service Connections</h2><p>In Azure DevOps, create or use a project (e.g. <strong>BI-Synapse</strong>) to contain your pipelines. Before creating the pipeline, set up service connections and other prerequisites:</p><ul><li><p><strong>Azure Service Principal:</strong> Create an Azure AD service principal that the pipeline will use for deployments. This SPN should have Contributor rights on the Azure resource group(s) containing your Synapse workspace and SQL resources, and it <strong>must be a Synapse Workspace Admin on the Synapse workspace</strong> to publish artifacts. It's recommended to create separate service principals for each environment’s subscription if they reside in different Azure subscriptions (for example, a <em>Dev SPN</em> for non-prod and a <em>Prod SPN</em> for production).</p></li><li><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212932.png" width="736" loading="lazy" src="attachments/3256156203/3256713276.png?width=736" data-image-src="attachments/3256156203/3256713276.png" data-height="715" data-width="1570" data-unresolved-comment-count="0" data-linked-resource-id="3256713276" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212932.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="07908bf0-aa96-4a9f-8c6b-a4b0bd75a2f3" data-media-type="file"></span></li><li><p><strong>Service Connection in DevOps:</strong> In your Azure DevOps project settings, go to <strong>Service Connections</strong> (under Pipelines) and create a new connection of type <strong>Azure Resource Manager</strong>. Choose <strong>Service principal (manual)</strong> and input the subscription ID, tenant ID, and client ID/secret of your service principal. Give the connection a recognizable name (include the environment name, e.g. <em>AzureRM-Prod</em>). Verify the connection succeeds and <strong>grant access</strong> to all pipelines if prompted. Repeat this for each environment or subscription as needed. In our scenario, for instance, a connection <strong>CraigslP-BI-Synapse-SPN-arg-aue-prpsi-biapp-01</strong> was created using a service principal with rights to the Prod resource group (arg-aue-prpsi-biapp-01). This connection will be used by pipeline tasks to authenticate to Azure.</p></li><li><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-212947.png" width="736" loading="lazy" src="attachments/3256156203/3256680510.png?width=736" data-image-src="attachments/3256156203/3256680510.png" data-height="720" data-width="1564" data-unresolved-comment-count="0" data-linked-resource-id="3256680510" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-212947.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="7255f954-7bb9-486d-86a0-71534018dac4" data-media-type="file"></span></li><li><p><strong>Agent Pool (Think Similarity of SQL Agents Job):</strong> Decide if you will use Microsoft-hosted agents or a self-hosted agent. </p></li><li><p>Azure DevOps hosted agents (like <em>windows-latest</em>) come pre-installed with tooling like Azure CLI, Powershell, and SqlPackage (for DACPAC deployment). </p></li><li><p>If you use a self-hosted agent (as in our example, an agent machine <code>waueppdbiarcir1</code> in pool <strong>BI-Synapse-dev</strong>), ensure the machine has required tools: <strong>SqlPackage</strong> for DACPAC deployments, Azure CLI or Az PowerShell (if using them), and the latest Azure DevOps agent software. You can register custom capabilities on the agent (for example, define a capability &quot;SqlPackage&quot; once it’s installed). </p></li><li><p>In the pipeline’s agent job, add a demand for <code>SqlPackage</code> so that the job only runs on an agent that has it. This ensures the DACPAC task can find the tool (the example pipeline uses a self-hosted agent with a demand for <code>sqlpackage</code> as shown below).</p></li></ul><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213612.png" width="760" loading="lazy" src="attachments/3256156203/3256647777.png?width=760" data-image-src="attachments/3256156203/3256647777.png" data-height="523" data-width="1388" data-unresolved-comment-count="0" data-linked-resource-id="3256647777" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213612.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="3fab4bcd-9ca9-4400-a40f-96d0feaa04cd" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213621.png" width="760" loading="lazy" src="attachments/3256156203/3256647783.png?width=760" data-image-src="attachments/3256156203/3256647783.png" data-height="656" data-width="1362" data-unresolved-comment-count="0" data-linked-resource-id="3256647783" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213621.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="1dc7e4d2-2971-4df6-903c-eb490e41ae8b" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213630.png" width="760" loading="lazy" src="attachments/3256156203/3256647789.png?width=760" data-image-src="attachments/3256156203/3256647789.png" data-height="737" data-width="1303" data-unresolved-comment-count="0" data-linked-resource-id="3256647789" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213630.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="698c4135-ddbc-4d60-9e3e-3d7d68bdc576" data-media-type="file"></span><p /><p /><h2 id="DataPlatformDevOpsWorkshopDay1-Part2-Part3-CreatingtheReleasePipelineinAzureDevOps">Part 3 - Creating the Release Pipeline in Azure DevOps</h2><p>Now, create the pipeline that will deploy the Synapse artifacts and DACPAC to target environments. We will describe using the <strong>Classic Release Pipeline</strong> UI (since our context uses the classic approach with separate release definitions per environment), but you could also implement this via YAML multi-stage pipelines. </p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213047.png" width="760" loading="lazy" src="attachments/3256156203/3256647733.png?width=760" data-image-src="attachments/3256156203/3256647733.png" data-height="730" data-width="1591" data-unresolved-comment-count="0" data-linked-resource-id="3256647733" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213047.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="fcbb5a4a-e074-4854-a22c-bfc1f1f397fa" data-media-type="file"></span><p>The high-level steps are:</p><ol start="1"><li><p><strong>Create a New Release Pipeline:</strong> In Azure DevOps, navigate to <strong>Pipelines &gt; Releases</strong>, and click <strong>New Pipeline</strong> (or <strong>New &gt; New release pipeline</strong> if others exist). Choose the <strong>Empty job</strong> template for a blank pipeline. Give a name to the pipeline (for example, <em>Bedrock - Deploy Synapse Analytics objects - Prod</em> for the production Synapse artifacts pipeline).</p></li><li><p><strong>Add an Artifact (Link the Source):</strong> Under <strong>Pipeline &gt; Artifacts</strong>, click <strong>Add</strong> and select the source type. If your Synapse ARM templates are in an Azure Repos Git repository, choose <strong>Azure Repos Git</strong> and select the project and repository (e.g. <em>Bedrock-BI-Synapse</em>). Choose the branch that contains the deployment files – this will be the <strong>workspace_publish</strong> branch for Synapse artifacts (as configured earlier). Use the latest version of that branch by default. This artifact ensures the pipeline has access to TemplateForWorkspace.json, TemplateParametersForWorkspace.json, and (for DACPAC) possibly the DACPAC file if it’s committed or produced by a build. If the DACPAC comes from a build pipeline, you can add a second artifact pointing to the build pipeline’s output. For example, add an artifact from the <strong>Build</strong> type, select the build pipeline that produces the DACPAC, and the latest successful build. You can have multiple artifacts in one release pipeline (one for Synapse template, one for DACPAC). In our scenario, the Synapse pipeline artifact came directly from the repo’s publish branch, while the database release pipeline likely took the DACPAC from a build artifact.</p></li><li><p><strong>Configure Continuous Trigger (optional):</strong> If you want deployments to run automatically when new artifacts are available, enable the <strong>continuous deployment trigger</strong> on the artifact. For instance, you might enable it on the Synapse publish branch artifact so that whenever a developer publishes new Synapse changes (pushing an updated TemplateForWorkspace.json), the release pipeline for test environment kicks off. Alternatively, you might prefer manual or scheduled deployments – choose what fits your process.</p></li><li><p><strong>Add Stages for Environments:</strong> In a single pipeline, you can create multiple stages (Dev, UAT, PreProd, Prod). For each stage, click <strong>Add a stage</strong> and name it accordingly. Inside each stage you will add tasks to deploy to that environment. In a multi-stage setup, you can define the order (e.g. Dev -&gt; UAT -&gt; PreProd -&gt; Prod) and add approvals or gates (like requiring a manual approval before Prod deployment). <strong>Alternatively</strong>, as shown in the context screenshots, you can maintain separate release pipelines per environment. For example, one pipeline dedicated to Prod, another to UAT, etc., each triggered intentionally. The principles of task configuration are the same, but using one pipeline with stages is generally easier to manage. This guide will assume a single pipeline with multiple stages (highlighting differences where needed).</p></li><li><p><strong>Define Pipeline Variables and Variable Groups:</strong> It’s important to externalize environment-specific settings (like resource names, connection strings, credentials) using variables. In Azure DevOps, go to <strong>Pipelines &gt; Library</strong> and create <strong>Variable Groups</strong> for your environments. For example, create a group <strong>Prod-variables</strong> containing entries like <code>vgKeyVaultUrl</code>, <code>vgOnpremUserName</code>, <code>vgSynapseADLS</code>, <code>vgWorkspaceName</code> (the actual values being the production Key Vault URL, on-prem username, ADLS account URL, Synapse workspace name, etc.). Do the same for UAT, Dev, etc., or use a single group with multiple variables scoped by environment if you prefer. Mark secrets (passwords, keys) as secret in the variable group and/or link them to Azure Key Vault secrets for security. Now, in the release pipeline, under the <strong>Variables</strong> tab, you can <strong>Link variable group</strong> to attach the appropriate group to the stage or pipeline. For instance, link <em>Prod-variables</em> to the Prod stage. This makes those variables available as $(vgKeyVaultUrl) etc. In our example, the pipeline defines variables like <code>KeyVaultUrl = $(vgKeyVaultUrl)</code> and <code>OnpremUserName = $(vgOnpremUserName)</code> – effectively pulling in the values from the variable group. Using variable groups ensures that when the same template is deployed to a different stage, it picks up that environment’s specific values (like the Dev KeyVault URL vs. Prod KeyVault URL).</p></li></ol><p>With the artifact(s) and variables in place, we can now configure the <strong>tasks</strong> in each stage to perform the deployment.</p><h2 id="DataPlatformDevOpsWorkshopDay1-Part2-Part4-DeploymentTasksConfigurationinthePipelineStages">Part 4 - Deployment Tasks Configuration in the Pipeline Stages</h2><p>Each stage will typically have two main tasks: </p><p>one to deploy Synapse workspace artifacts via ARM template, </p><p>and one to deploy the database DACPAC. </p><h3 id="DataPlatformDevOpsWorkshopDay1-Part2-4.1SynapseWorkspaceArtifactsDeploymentTask">4.1 Synapse Workspace Artifacts Deployment Task</h3><p>To deploy Synapse Analytics artifacts (pipelines, datasets, triggers, notebooks, etc.) from the published template, Azure DevOps uses a specialized task called <strong>Synapse workspace deployment</strong>. This task comes from an Azure DevOps extension, so first ensure the extension <em>Azure Synapse Workspace Deployment</em> is installed in your organization (a Microsoft Entra admin can install it from the Visual Studio Marketplace). </p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213406.png" width="760" loading="lazy" src="attachments/3256156203/3256647750.png?width=760" data-image-src="attachments/3256156203/3256647750.png" data-height="732" data-width="1359" data-unresolved-comment-count="0" data-linked-resource-id="3256647750" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213406.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="4d55e57d-5e0a-40fb-be59-1c0422f01e2a" data-media-type="file"></span><p /><p>Once installed, you can add this task to your pipeline stage:</p><ul><li><p><strong>Add the Synapse Deployment Task:</strong> In the stage (e.g. Prod stage) click <strong>+</strong> to add a task. Search for &quot;Synapse workspace deployment&quot; and add it. (If it’s not found, the extension may not be installed or you might need to refresh the browser after installation.) You will see a task form titled <strong>Synapse workspace deployment</strong> (version 1 or 2).</p></li><li><p><strong>Select Template and Parameters:</strong> In the task settings, set the <strong>Template file</strong> path to the ARM template JSON (TemplateForWorkspace.json) from the artifact. For example: <code>$(System.DefaultWorkingDirectory)/_Bedrock-BI-Synapse/synWorkspace/TemplateForWorkspace.json</code> (the exact path depends on your repo structure; you can browse and select the file). Similarly, set the <strong>Template parameters file</strong> to TemplateParametersForWorkspace.json. This tells the task what to deploy. The screenshot below shows an example configuration of this task in the pipeline UI, including the template paths and other settings for a Prod deployment stage.</p></li><li><p><strong>Azure Connection and Target Details:</strong> Next, choose the Azure connection (service principal) for this deployment. In the <strong>Azure subscription</strong> or <strong>Service connection</strong> field, select the service connection corresponding to the target environment (e.g. the Prod ARM service connection). Then specify the <strong>Resource Group</strong> name where your target Synapse workspace resides, and the <strong>Synapse Workspace Name</strong> of the target environment. These values can be entered directly or come from variables (for instance, you might set Resource Group = <code>arg-aue-prpsi-biapp-01</code> and Workspace = the prod workspace name, or use something like <code>$(vgworkspaceName)</code> if you stored it in the variable group).</p></li><li><p><strong>Override Parameters:</strong> The Synapse ARM template parameters file contains many parameters (e.g. workspace name, SQL server names, Linked Service connection strings, etc.). Some of these need to be overridden for each environment. Click <strong>Override template parameters</strong> to specify environment-specific values. For example, you might override:</p></li><li><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213426.png" width="643" loading="lazy" src="attachments/3256156203/3256615002.png?width=643" data-image-src="attachments/3256156203/3256615002.png" data-height="721" data-width="643" data-unresolved-comment-count="0" data-linked-resource-id="3256615002" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213426.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="4426ec5b-ea74-477a-96dc-fc441d254d5c" data-media-type="file"></span><p /><ul><li><p><code>workspaceName</code> to the target workspace’s actual name (if different from dev’s name).</p></li><li><p>Linked service parameters for storage accounts or key vaults, e.g. set the production Data Lake Storage account URL (<code>*storage_properties_typeProperties_url</code>) to the Prod ADLS URL, and the Key Vault base URL (<code>*KeyVault_properties_typeProperties_baseUrl</code>) to the Prod Key Vault URL.</p></li><li><p>Credentials for on-prem data sources: if multiple linked services use the same on-prem username, you might override those parameters with a variable like <code>$(vgOnpremUserName)</code> (as was done in the example, where many linked service username parameters were set to the same variable)</p></li></ul><p>You can use the variables from the variable group by referencing them as <code>$(VariableName)</code>. For secure values like passwords, ensure they are in Key Vault or stored as secure variables and passed appropriately (often the template will reference Key Vault secrets, so you only need to supply the Key Vault name/URL). The goal is to ensure the ARM deployment uses correct endpoints and secrets for that environment.</p></li></ul><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213448.png" width="760" loading="lazy" src="attachments/3256156203/3256713286.png?width=760" data-image-src="attachments/3256156203/3256713286.png" data-height="551" data-width="1370" data-unresolved-comment-count="0" data-linked-resource-id="3256713286" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213448.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="564fe57e-4970-4a6e-9e63-283ad13bffa3" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213511.png" width="760" loading="lazy" src="attachments/3256156203/3256680530.png?width=760" data-image-src="attachments/3256156203/3256680530.png" data-height="736" data-width="1364" data-unresolved-comment-count="0" data-linked-resource-id="3256680530" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213511.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="5cb3491a-0537-4d40-8f2d-9bae7a478187" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213521.png" width="760" loading="lazy" src="attachments/3256156203/3256647758.png?width=760" data-image-src="attachments/3256156203/3256647758.png" data-height="756" data-width="1393" data-unresolved-comment-count="0" data-linked-resource-id="3256647758" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213521.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="401b1eea-328d-4906-935f-456e6bdd1684" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213529.png" width="760" loading="lazy" src="attachments/3256156203/3256680537.png?width=760" data-image-src="attachments/3256156203/3256680537.png" data-height="477" data-width="1584" data-unresolved-comment-count="0" data-linked-resource-id="3256680537" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213529.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="66eace72-592c-4896-aa64-daf61ea0756f" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213537.png" width="760" loading="lazy" src="attachments/3256156203/3256647764.png?width=760" data-image-src="attachments/3256156203/3256647764.png" data-height="640" data-width="1320" data-unresolved-comment-count="0" data-linked-resource-id="3256647764" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213537.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="7baf0353-d578-4a6e-b2a9-6b65ff641e11" data-media-type="file"></span><p /><ul><li><p><strong>Additional Settings:</strong> You may enable <strong>Delete artifacts not in template</strong> (if using Synapse workspace deployment task 2.x) to keep the target in sync. This option will remove any artifacts in the target workspace that are not present in the ARM template being deployed (useful to prevent drift or to delete resources that were removed in development). Also, ensure <strong>Operation</strong> is set to &quot;deploy&quot;. The task will automatically handle deployment of all Synapse artifacts. <em>(Note: The Synapse deployment task focuses on workspace artifacts. It does <strong>not</strong> create the workspace itself, nor Spark pools or Integration Runtimes – those resources should be pre-provisioned in the target environment as prerequisites.)</em></p></li><li><p><strong>Security and Permissions:</strong> As noted, the service principal used must be a Synapse Admin on the target workspace (to publish artifacts inside the workspace) in addition to having Resource Group contributor rights. If you encounter permission errors, double-check the RBAC roles and Synapse Studio access control for that SPN.</p></li></ul><p>When this task runs, it will deploy all the Synapse artifacts from the ARM template to the target Synapse workspace. For example, it will create or update pipelines, datasets, data flows, notebooks, and triggers. By default, triggers in Synapse (or Data Factory) are deployed in a <strong>stopped</strong> state for safety. The newer versions of the task have an option to toggle triggers on; otherwise, you may need to manually re-enable triggers in Synapse Studio or script their activation after deployment. Verify the deployment by checking the target workspace via Synapse Studio – you should see all the expected artifacts after the pipeline runs.</p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213550.png" width="760" loading="lazy" src="attachments/3256156203/3256647770.png?width=760" data-image-src="attachments/3256156203/3256647770.png" data-height="720" data-width="1574" data-unresolved-comment-count="0" data-linked-resource-id="3256647770" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213550.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="fe803d54-827a-460e-9410-c77d3f2ae866" data-media-type="file"></span><p /><h3 id="DataPlatformDevOpsWorkshopDay1-Part2-2.DACPACSQLDatabaseDeploymentTask">2. DACPAC SQL Database Deployment Task</h3><p>The next part of the pipeline stage is deploying the database changes using the DACPAC. Azure DevOps provides the <strong>Azure SQL Database Deployment</strong> task (also known by its task name <code>SqlAzureDacpacDeployment@1</code>, and in the classic UI labeled <strong>Azure SQL DACPAC</strong> or <strong>SQL Database Deploy</strong>). This task will take a DACPAC file and publish it to an Azure SQL Database or Azure Synapse SQL pool. </p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213758.png" width="760" loading="lazy" src="attachments/3256156203/3256647796.png?width=760" data-image-src="attachments/3256156203/3256647796.png" data-height="685" data-width="1303" data-unresolved-comment-count="0" data-linked-resource-id="3256647796" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213758.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="fc9a2796-e2e4-47a1-8a97-d2688d475db2" data-media-type="file"></span><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size"><img class="confluence-embedded-image image-center" alt="image-20250717-213804.png" width="760" loading="lazy" src="attachments/3256156203/3256647802.png?width=760" data-image-src="attachments/3256156203/3256647802.png" data-height="709" data-width="1363" data-unresolved-comment-count="0" data-linked-resource-id="3256647802" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-20250717-213804.png" data-base-url="https://craigsip.atlassian.net/wiki" data-linked-resource-content-type="image/png" data-linked-resource-container-id="3256156203" data-linked-resource-container-version="2" data-media-id="cf280576-b975-40f9-bb51-4e0ca4ef7983" data-media-type="file"></span><p>Here’s how to set it up:</p><ul><li><p><strong>Add the DACPAC Deployment Task:</strong> In the stage tasks, click <strong>+</strong> and search for &quot;SQL&quot; or &quot;Dacpac&quot;. Add the <strong>Azure SQL Database Deployment</strong> task. You might rename it to something like &quot;Deploy DACPAC to Prod SQL Pool&quot;. If using YAML, the task reference is <code>SqlAzureDacpacDeployment@1</code> with appropriate inputs. In our example, the release stage for the framework database had a single task of this type to deploy the DACPAC schema changes.</p></li><li><p><strong>Select DACPAC File:</strong> In the task settings, specify the path to the <strong>.dacpac</strong> file to deploy. If the DACPAC is part of the artifact from a build, you can browse the artifact’s drop folder. For instance, it might be something like <code>$(System.DefaultWorkingDirectory)/_DB_Build/drop/Database.dacpac</code>. If you included the DACPAC in the same repo artifact, it could be under the repo path. The key is to point the task to the compiled DACPAC package. In the UI, there's typically a file picker for this. (In a previous step of our workflow, the DACPAC would have been produced by a build pipeline – ensure that artifact is linked so the file is available.) As a reference, after building the project, a release pipeline will deploy that DACPAC to the next environment using this task, essentially just selecting the DACPAC file and deploying it.</p></li><li><p><strong>Azure Subscription and Server/Database Details:</strong> Choose the Azure subscription or service connection for the SQL deployment. This can be the same service connection used for Synapse if the database is in the same Azure context. Then specify the <strong>Target Server Name</strong> and <strong>Database Name</strong>. For an Azure SQL Database, the server name is the fully qualified name (e.g. <a class="external-link" href="http://myserver.database.windows.net" rel="nofollow"><em>myserver.database.windows.net</em></a>). For a Synapse dedicated SQL pool, use the workspace’s SQL endpoint (e.g. <a class="external-link" href="http://myworkspace.sql.azuresynapse.net" rel="nofollow"><em>myworkspace.sql.azuresynapse.net</em></a>) and the dedicated pool name as the database. The task allows various authentication methods:</p><ul><li><p><strong>SQL Server Authentication:</strong> Easiest for initial setup – provide the <strong>SQL admin username</strong> (e.g. <em>sqladmin</em>) and <strong>password</strong> for the target server. You should store the password as a secret variable (in a variable group or the pipeline) and reference it here. Mark the password field as sensitive so it doesn’t log. Ensure this SQL admin user has rights to deploy (server admin or db owner).</p></li><li><p><strong>Azure AD Authentication:</strong> Alternatively, you can use Azure AD credentials or even the service principal to authenticate (the task supports AAD password auth or service principal auth). This requires that the SPN or AAD user is set up as an Azure AD admin on the SQL server or has appropriate roles. For simplicity, many use SQL auth for deployments.</p></li><li><p><strong>Connection string:</strong> The task also has an option for using a direct connection string (if you select Authentication Type = connection string). You could use this to include the username/password in one string or use an AAD connection string. However, using the fields is straightforward and the task will construct the connection string.</p></li></ul></li><li><p><strong>Task Settings:</strong> Ensure <strong>Deploy type</strong> is DACPAC (the default) and <strong>Deployment Action</strong> is <strong>Publish</strong> (to apply changes). By default, the task will <strong>Auto-detect Azure SQL server firewall</strong> and open a firewall exception for the deployment if needed. This is very useful: if using a hosted agent with a dynamic IP, the task can create a firewall rule to allow the IP and then remove it after deployment (the setting <strong>Delete firewall rule after task</strong> is true by default). If your SQL server has &quot;Allow Azure services&quot; enabled or the agent is on a VM inside the same VNet, you might not need this, but it’s nice to leave on for safety.</p></li><li><p><strong>Optional SqlPackage Arguments:</strong> You can specify additional <strong>SqlPackage.exe</strong> parameters if needed. For instance, one common addition is <code>/p:BlockOnPossibleDataLoss=False</code> to allow deployments that involve dropping tables or other data-loss changes. You can add this in the <strong>Additional Arguments</strong> field if your deployment scenario calls for it (use with caution and process approvals for destructive changes). You can also include pre or post deployment script execution if using a SQL script task, but typically the DACPAC handles schema diffs.</p></li><li><p><strong>Agent Demands:</strong> As noted earlier, ensure the agent running this task has <strong>SqlPackage</strong>. On Microsoft-hosted Windows agents, it’s available. On self-hosted, you might need to install the latest Data-Tier Application Framework or SQL Server SDK which includes SqlPackage. In our pipeline, we explicitly added a <strong>demand</strong> for &quot;sqlpackage&quot; on the agent job – this means the job will only run on an agent that has a capability named &quot;sqlpackage&quot;. We registered that capability on our self-hosted agent after installing the tool. If using hosted agents, you typically don’t need to add this demand (but it doesn’t hurt).</p></li></ul><p>When configured, this task will connect to the target database and publish the DACPAC, applying any schema changes. It will output the results of the deployment (e.g. which tables or procedures were added/modified) in the log. After running, you can verify the target database has the expected schema (and reference data, if included in the project).</p><p><strong>Tip:</strong> If your DACPAC deployment needs to target multiple databases or multiple DACPACs (say, a separate “framework” database and a “analytics” database), you can include multiple tasks or separate stages for each. In the context screenshots, for example, there was a pipeline specifically for a “Framework Database” DACPAC release. Structure your pipelines in a way that makes sense (either one pipeline handles both Synapse and one DB, or you break them out). Just be consistent so that junior engineers can easily find which pipeline deploys what.</p><h2 id="DataPlatformDevOpsWorkshopDay1-Part2-RunningthePipeline:DeploymentFlowAcrossEnvironments">Running the Pipeline: Deployment Flow Across Environments</h2><p>Once the pipeline is set up with artifacts, variables, and tasks, the CI/CD process can be executed:</p><ul><li><p><strong>Triggering Deployments:</strong> If you configured continuous triggers, a commit or publish action will automatically create a release run. Otherwise, you can manually create a release by clicking <strong>Create Release</strong>, selecting the pipeline and the artifact versions. For instance, after a Synapse publish, you might manually trigger a Dev or UAT release for testing. In a multi-stage pipeline, the Dev stage might deploy immediately, then after validation, you approve and continue to UAT, and so on until Prod.</p></li><li><p><strong>Deployment Sequence:</strong> The pipeline will deploy environment by environment. In a single pipeline with stages, Azure DevOps will run the Dev stage tasks (Synapse deployment, DACPAC, etc.), then move to the next stage. In separate pipelines per env, you’d run the pipeline designated for that env. In either case, only the artifacts from the specified artifact version are used, so all environments get the same version of artifacts for a given release cycle.</p></li><li><p><strong>Monitoring and Logs:</strong> Azure DevOps provides detailed logs for each task. You can watch the pipeline in real-time or review logs after. Each release or run will show a status (✓ for success, ✕ for failure). In the release history, you can see past deployments for each stage – useful for auditing. In our scenario, for example, we could see that <em>Release-4</em> of <strong>Release Framework Database to Dev</strong> succeeded (green check) while <em>Release-3</em> might have failed (red X) in the logs. By clicking on a stage, you can inspect where a failure occurred – e.g. if the DACPAC publish had an error, or the Synapse ARM deployment had an issue.</p></li><li><p><strong>Verification:</strong> After a stage succeeds, verify the target environment:</p><ul><li><p>For Synapse: open Synapse Studio for the target workspace, check that new pipelines/datasets are present, triggers are deployed (they might be off – you can turn them on if everything looks good), and any linked services are properly connected (they will use the new Key Vault or credentials you provided).</p></li><li><p>For the Database: connect to the SQL database (e.g. via SSMS or Azure Data Studio) and verify the schema changes. You might also run some smoke tests or queries to ensure the new changes are working as expected.</p></li></ul></li><li><p><strong>Promoting to Next Stage:</strong> If using approvals, a Prod stage might be waiting for approval – a team lead or release manager can review UAT results and then approve the Prod deployment. Azure DevOps will then use the <em>same</em> artifact (same template and DACPAC) to deploy to Prod, but using the Prod variables and connections.</p></li></ul><p>Throughout this process, Azure DevOps maintains a history. You can always go back to a previous release to see what was deployed, when, and by whom (helpful for compliance and debugging).</p><h2 id="DataPlatformDevOpsWorkshopDay1-Part2-TroubleshootingandBestPractices">Troubleshooting and Best Practices</h2><p>Even with a solid setup, you may encounter issues. Here are common troubleshooting tips and best practices:</p><ul><li><p><strong>Service Connection &amp; Permissions:</strong> If the Synapse deployment task fails with authorization errors, ensure the service principal has the required roles. It needs at least <strong>Contributor</strong> on the resource group or Synapse workspace, and the <strong>Synapse Administrator</strong> or <strong>Synapse Artifact Publisher</strong> role within the Synapse workspace for artifact deployment. If the DACPAC task fails to connect, ensure the SQL server allows the connection (check that the firewall is not blocking the DevOps agent and that the credentials are correct).</p></li><li><p><strong>Workspace Preparation:</strong> The target Synapse workspace should be created and ready. Do not configure Git on target workspaces (the workspace should be in live mode). If the workspace or Spark pools don’t exist, the deployment will fail – deploy those via ARM or Azure CLI beforehand or include an ARM template stage to create them. Remember, the Synapse artifact deployment does not handle provisioning pools or the workspace itself.</p></li><li><p><strong>ARM Template Parameterization:</strong> Sometimes you might notice that certain things weren’t parameterized in TemplateParametersForWorkspace.json (for example, if a linked service property didn’t appear as a parameter). Azure Synapse by default parameterizes most secure values and resource references, but if something is missing, you have options:</p><ul><li><p>Manually add an override in the pipeline (as we did with some on-premises linked service usernames).</p></li><li><p>Use a <strong>custom parameters template</strong> in Synapse (a file named <em>template-parameters-definition.json</em> in your repository) to force parameterization of additional properties. This is an advanced step: you define which sections of the workspace ARM template should become parameters. If your scenario requires it, refer to Synapse CI/CD documentation for how to set this up.</p></li><li><p>Another approach (if not using the extension) is to preprocess the parameters JSON in a script to swap values (the Analytics Lab guide demonstrates using a PowerShell script to replace values in the parameters file before deployment, but the extension’s override feature often suffices).</p></li></ul></li><li><p><strong>Synapse Deployment Failures:</strong> If the Synapse task fails, look at the error message in the log. Common issues include mis-typed resource names, the service principal not having access to a Key Vault (if your linked services use Key Vault, the SPN also needs at least GET access to the secrets in that Key Vault), or attempting to deploy a trigger while its pipeline hasn’t been deployed (usually the task handles ordering). Also, if a trigger is scheduled, ensure that integration runtime or dependencies exist. Most issues can be resolved by adjusting parameters or permissions.</p></li><li><p><strong>DACPAC Deployment Issues:</strong> If the DACPAC task fails, check the log for the detailed SqlPackage error. Possible issues:</p><ul><li><p><em>Schema drift or conflicts:</em> The DACPAC may fail if the target has unexpected existing objects. Make sure the target DB is in a known state or use a drift report ahead of time.</p></li><li><p><em>Missing permissions:</em> The user might not have privileges to alter the schema. Ensure the login used has db_owner or appropriate DDL rights on the database.</p></li><li><p><em>Firewall:</em> If you see a timeout or connection error, it’s likely firewall. The task’s auto-firewall should handle it, but if not, you may need to manually allow the agent IP or turn on “Allow Azure services” on the server for the duration of deployment. Using service endpoints or a self-hosted agent in the same network as the DB can also help.</p></li><li><p><em>Blocking changes:</em> If you see an error about potential data loss (and you intend to drop or alter columns), you may need to set <code>/p:BlockOnPossibleDataLoss=False</code> in additional arguments to allow it. Be cautious and ensure this is an intended deployment action.</p></li><li><p><em>Tooling:</em> Ensure the DACPAC is valid. If you manually stored a DACPAC, make sure it’s updated. If using a build pipeline, ensure the build succeeded and the artifact was properly referenced. Always double-check the path to the DACPAC in the release task if the artifact source or name changed.</p></li></ul></li><li><p><strong>Pipeline Organization:</strong> For maintainability, document your pipeline for the team:</p><ul><li><p>Use descriptive names for tasks (e.g. “Deploy Synapse Artifacts to UAT” rather than just “Synapse deployment task”).</p></li><li><p>Group tasks logically (the classic UI runs them sequentially, but you can visually separate by adding empty dummy tasks with labels like “--- Deploy Synapse ---” if needed).</p></li><li><p>Keep variable names consistent across environments (e.g. always use <code>vgKeyVaultUrl</code> in all groups, just values differ). This consistency helps junior engineers quickly map what’s happening.</p></li><li><p>Leverage <strong>Variable Groups</strong> and <strong>Pipeline Variables</strong> to avoid hard-coding values in tasks. This makes promoting changes or reusing pipeline definitions easier.</p></li></ul></li><li><p><strong>Testing and Validation:</strong> It’s a good practice to test your pipeline in a lower environment first. For example, do a trial run of the deployment to a dev/test workspace and a dummy database before pointing to production. This will catch any issues with the tasks or parameters in a safe environment. You can even create a special “Sandbox” stage for pipeline testing.</p></li><li><p><strong>Use of Approvals:</strong> For production deployments, use Azure DevOps <strong>Pre-deployment approvals</strong>. This means even if the pipeline triggers automatically, it will pause before Prod until an authorized person reviews and approves. This adds control and an opportunity to check that UAT was successful.</p></li><li><p><strong>Maintain the Synapse ARM Template:</strong> Always encourage the Synapse developers to hit the <strong>Publish</strong> button in Synapse Studio whenever a set of changes is ready, to update the workspace_publish branch. The CI/CD pipeline relies on that TemplateForWorkspace.json being current. If something was changed only in the workspace live mode and not published, it won’t be captured in source control. Training the team on this process is important.</p></li></ul><p>By following these steps and tips, a junior data engineer should be able to understand and manage the Azure DevOps pipelines for deploying Synapse Analytics workspace artifacts and SQL database projects via DACPAC. The pipeline automation will greatly speed up deployments and reduce manual errors, providing a repeatable process for promoting changes from development through to production in your data platform. With the above guide and some hands-on practice, onboarding to this CI/CD setup becomes much smoother. Good luck with your deployments!</p><p><strong>Sources:</strong> Continuous integration &amp; delivery for Azure Synapse, Azure Synapse CI/CD Q&amp;A, Azure DevOps DACPAC Deployment Tips.</p>
                    </div>

                                        <div class="pageSection group">
                        <div class="pageSectionHeader">
                            <h2 id="attachments" class="pageSectionTitle">Attachments:</h2>
                        </div>

                        <div class="greybox" align="left">
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256680476.png">image-20250717-212358.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256614972.png">image-20250717-212518.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256680484.png">image-20250717-212544.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256713258.png">image-20250717-212552.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256680491.png">image-20250717-212559.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256614980.png">image-20250717-212623.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256713269.png">image-20250717-212852.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256713276.png">image-20250717-212932.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256680510.png">image-20250717-212947.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647733.png">image-20250717-213047.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647750.png">image-20250717-213406.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256615002.png">image-20250717-213426.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256713286.png">image-20250717-213448.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256680530.png">image-20250717-213511.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647758.png">image-20250717-213521.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256680537.png">image-20250717-213529.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647764.png">image-20250717-213537.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647770.png">image-20250717-213550.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647777.png">image-20250717-213612.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647783.png">image-20250717-213621.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647789.png">image-20250717-213630.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647796.png">image-20250717-213758.png</a> (image/png)
                                <br/>
                                                            <img src="images/icons/bullet_blue.gif" height="8" width="8" alt=""/>
                                <a href="attachments/3256156203/3256647802.png">image-20250717-213804.png</a> (image/png)
                                <br/>
                                                    </div>
                    </div>
                    
                                                      
                </div>             </div> 
            <div id="footer" role="contentinfo">
                <section class="footer-body">
                    <p>Document generated by Confluence on 18-08-25 20:54</p>
                    <div id="footer-logo"><a href="http://www.atlassian.com/">Atlassian</a></div>
                </section>
            </div>
        </div>     </body>
</html>
